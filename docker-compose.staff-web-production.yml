version: '3.9'

# Production Docker Compose for Staff-Web V2 System
# Complete production-ready deployment with React frontend and Django backend

volumes:
  naga_postgres_data: {}
  naga_postgres_data_backups: {}
  naga_traefik: {}
  naga_django_media: {}
  naga_django_static: {}
  naga_redis_data: {}
  naga_staff_web_static: {}
  naga_uptime_kuma_data: {}
  naga_netdata_config: {}
  naga_netdata_lib: {}
  naga_netdata_cache: {}
  naga_prometheus_data: {}
  naga_grafana_data: {}
  naga_loki_data: {}

networks:
  traefik-proxy:
    external: true
  backend:
    driver: bridge
  monitoring:
    driver: bridge

services:
  # Backend Django Application
  django: &django
    build:
      context: ./backend
      dockerfile: ./compose/production/django/Dockerfile
      args:
        PYTHON_VERSION: 3.13.7
    image: naga_django_prod:latest
    container_name: naga_django_staff_web
    restart: unless-stopped
    volumes:
      - naga_django_media:/app/mediafiles
      - naga_django_static:/app/staticfiles
    networks:
      - backend
      - traefik-proxy
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - ./.envs/.production/.django
      - ./.envs/.production/.postgres
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.production
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - CELERY_BROKER_URL=${REDIS_URL}
      - DJANGO_ALLOWED_HOSTS=${DOMAIN_NAME},api.${DOMAIN_NAME}
      - DJANGO_CORS_ALLOWED_ORIGINS=https://${DOMAIN_NAME},https://staff.${DOMAIN_NAME}
    command: /start
    healthcheck:
      test:
        [
          'CMD',
          'python',
          '-c',
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/health-check/')",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    labels:
      - traefik.enable=true
      - traefik.docker.network=traefik-proxy
      - traefik.http.routers.django-api.rule=Host(`api.${DOMAIN_NAME}`)
      - traefik.http.routers.django-api.entrypoints=websecure
      - traefik.http.routers.django-api.tls=true
      - traefik.http.routers.django-api.tls.certresolver=letsencrypt
      - traefik.http.services.django-api.loadbalancer.server.port=8000
      # Security middleware
      - traefik.http.middlewares.api-ratelimit.ratelimit.burst=100
      - traefik.http.middlewares.api-ratelimit.ratelimit.average=50
      - traefik.http.routers.django-api.middlewares=api-ratelimit

  # Staff Web React Frontend
  staff-web:
    build:
      context: ./staff-web
      dockerfile: ./docker/Dockerfile.production
      args:
        NODE_VERSION: 20
        VITE_API_BASE_URL: https://api.${DOMAIN_NAME}
        VITE_WS_URL: wss://api.${DOMAIN_NAME}
    image: naga_staff_web_prod:latest
    container_name: naga_staff_web
    restart: unless-stopped
    volumes:
      - naga_staff_web_static:/usr/share/nginx/html:ro
    networks:
      - traefik-proxy
    environment:
      - NODE_ENV=production
      - VITE_API_BASE_URL=https://api.${DOMAIN_NAME}
      - VITE_WS_URL=wss://api.${DOMAIN_NAME}
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:80/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    labels:
      - traefik.enable=true
      - traefik.docker.network=traefik-proxy
      - traefik.http.routers.staff-web.rule=Host(`staff.${DOMAIN_NAME}`)
      - traefik.http.routers.staff-web.entrypoints=websecure
      - traefik.http.routers.staff-web.tls=true
      - traefik.http.routers.staff-web.tls.certresolver=letsencrypt
      - traefik.http.services.staff-web.loadbalancer.server.port=80
      # Security headers
      - traefik.http.middlewares.staff-security.headers.browserxssfilter=true
      - traefik.http.middlewares.staff-security.headers.contenttypenosniff=true
      - traefik.http.middlewares.staff-security.headers.frameDeny=true
      - traefik.http.middlewares.staff-security.headers.sslredirect=true
      - traefik.http.middlewares.staff-security.headers.stsSeconds=31536000
      - traefik.http.middlewares.staff-security.headers.stsIncludeSubdomains=true
      - traefik.http.middlewares.staff-security.headers.stsPreload=true
      - traefik.http.routers.staff-web.middlewares=staff-security

  # PostgreSQL Database
  postgres:
    build:
      context: ./backend
      dockerfile: ./compose/production/postgres/Dockerfile
    image: naga_postgres_prod:latest
    container_name: naga_postgres_staff_web
    restart: unless-stopped
    volumes:
      - naga_postgres_data:/var/lib/postgresql/data
      - naga_postgres_data_backups:/backups
    networks:
      - backend
    env_file:
      - ./.envs/.production/.postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST_AUTH_METHOD=md5
    command:
      - postgres
      - -c
      - max_connections=200
      - -c
      - shared_buffers=256MB
      - -c
      - effective_cache_size=1GB
      - -c
      - maintenance_work_mem=64MB
      - -c
      - checkpoint_completion_target=0.9
      - -c
      - wal_buffers=16MB
      - -c
      - default_statistics_target=100
      - -c
      - random_page_cost=1.1
      - -c
      - effective_io_concurrency=200
      - -c
      - work_mem=4MB
      - -c
      - min_wal_size=1GB
      - -c
      - max_wal_size=4GB
      - -c
      - log_statement=all
      - -c
      - log_duration=on
      - -c
      - log_min_duration_statement=1000
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

  # Redis Cache and Session Store
  redis:
    image: redis:7.2-alpine
    container_name: naga_redis_staff_web
    restart: unless-stopped
    volumes:
      - naga_redis_data:/data
    networks:
      - backend
    command:
      - redis-server
      - --appendonly
      - 'yes'
      - --maxmemory
      - 512mb
      - --maxmemory-policy
      - allkeys-lru
      - --save
      - '900 1'
      - --save
      - '300 10'
      - --save
      - '60 10000'
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # Celery Worker for Background Tasks
  celery-worker:
    <<: *django
    image: naga_celery_worker_prod:latest
    container_name: naga_celery_worker_staff_web
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      django:
        condition: service_healthy
    command: /start-celery-worker
    healthcheck:
      test:
        [
          'CMD',
          'python',
          'manage.py',
          'shell',
          '-c',
          "import celery; print('OK')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'
    labels:
      - traefik.enable=false

  # Celery Beat Scheduler
  celery-beat:
    <<: *django
    image: naga_celery_beat_prod:latest
    container_name: naga_celery_beat_staff_web
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      django:
        condition: service_healthy
    command: /start-celery-beat
    volumes:
      - naga_django_media:/app/mediafiles
    healthcheck:
      test:
        [
          'CMD',
          'python',
          'manage.py',
          'shell',
          '-c',
          "import celery; print('OK')",
        ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    labels:
      - traefik.enable=false

  # Traefik Reverse Proxy
  traefik:
    image: traefik:v3.0
    container_name: naga_traefik_staff_web
    restart: unless-stopped
    command:
      - --api.dashboard=true
      - --api.debug=false
      - --log.level=INFO
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --providers.docker.network=traefik-proxy
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}
      - --certificatesresolvers.letsencrypt.acme.storage=/acme.json
      - --certificatesresolvers.letsencrypt.acme.httpchallenge=true
      - --certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web
      - --global.checkNewVersion=false
      - --global.sendAnonymousUsage=false
      # Security
      - --serversTransport.insecureSkipVerify=false
      - --providers.docker.defaultRule=HostRegexp(`{catchall:.*}`)
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - naga_traefik:/acme.json
    networks:
      - traefik-proxy
    environment:
      - TRAEFIK_API_DASHBOARD=${TRAEFIK_DASHBOARD_ENABLED:-false}
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:8080/ping']
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'
    labels:
      - traefik.enable=true
      - traefik.http.routers.traefik.rule=Host(`traefik.${DOMAIN_NAME}`)
      - traefik.http.routers.traefik.entrypoints=websecure
      - traefik.http.routers.traefik.tls=true
      - traefik.http.routers.traefik.tls.certresolver=letsencrypt
      - traefik.http.routers.traefik.service=api@internal
      # Redirect HTTP to HTTPS
      - traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)
      - traefik.http.routers.http-catchall.entrypoints=web
      - traefik.http.routers.http-catchall.middlewares=redirect-to-https
      - traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https
      - traefik.http.middlewares.redirect-to-https.redirectscheme.permanent=true

  # Database Backup Service
  postgres-backup:
    image: prodrigestivill/postgres-backup-local:15
    container_name: naga_postgres_backup_staff_web
    restart: unless-stopped
    volumes:
      - naga_postgres_data_backups:/backups
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_EXTRA_OPTS=-Z6 --schema=public --blobs
      - SCHEDULE=@daily
      - BACKUP_KEEP_DAYS=30
      - BACKUP_KEEP_WEEKS=8
      - BACKUP_KEEP_MONTHS=6
      - HEALTHCHECK_PORT=8080
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:8080/']
      interval: 60s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Monitoring Services
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: naga_prometheus_staff_web
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules/:/etc/prometheus/rules/:ro
      - naga_prometheus_data:/prometheus
    networks:
      - monitoring
      - traefik-proxy
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:9090/-/healthy']
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    labels:
      - traefik.enable=true
      - traefik.docker.network=traefik-proxy
      - traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN_NAME}`)
      - traefik.http.routers.prometheus.entrypoints=websecure
      - traefik.http.routers.prometheus.tls=true
      - traefik.http.routers.prometheus.tls.certresolver=letsencrypt
      - traefik.http.services.prometheus.loadbalancer.server.port=9090

  grafana:
    image: grafana/grafana:10.1.0
    container_name: naga_grafana_staff_web
    restart: unless-stopped
    volumes:
      - naga_grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - monitoring
      - traefik-proxy
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SERVER_DOMAIN=${DOMAIN_NAME}
      - GF_SERVER_ROOT_URL=https://grafana.${DOMAIN_NAME}
      - GF_SMTP_ENABLED=${GRAFANA_SMTP_ENABLED:-false}
      - GF_SMTP_HOST=${GRAFANA_SMTP_HOST:-}
      - GF_SMTP_USER=${GRAFANA_SMTP_USER:-}
      - GF_SMTP_PASSWORD=${GRAFANA_SMTP_PASSWORD:-}
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:3000/api/health']
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'
    labels:
      - traefik.enable=true
      - traefik.docker.network=traefik-proxy
      - traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN_NAME}`)
      - traefik.http.routers.grafana.entrypoints=websecure
      - traefik.http.routers.grafana.tls=true
      - traefik.http.routers.grafana.tls.certresolver=letsencrypt
      - traefik.http.services.grafana.loadbalancer.server.port=3000

  # Log Aggregation
  loki:
    image: grafana/loki:2.9.0
    container_name: naga_loki_staff_web
    restart: unless-stopped
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - naga_loki_data:/loki
    networks:
      - monitoring
    command: -config.file=/etc/loki/local-config.yaml
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:3100/ready']
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Uptime Monitoring
  uptime-kuma:
    image: louislam/uptime-kuma:1.23.8
    container_name: naga_uptime_kuma_staff_web
    restart: unless-stopped
    volumes:
      - naga_uptime_kuma_data:/app/data
    networks:
      - monitoring
      - traefik-proxy
    environment:
      - UPTIME_KUMA_DISABLE_FRAME_SAMEORIGIN=1
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost:3001']
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    labels:
      - traefik.enable=true
      - traefik.docker.network=traefik-proxy
      - traefik.http.routers.uptime-kuma.rule=Host(`uptime.${DOMAIN_NAME}`)
      - traefik.http.routers.uptime-kuma.entrypoints=websecure
      - traefik.http.routers.uptime-kuma.tls=true
      - traefik.http.routers.uptime-kuma.tls.certresolver=letsencrypt
      - traefik.http.services.uptime-kuma.loadbalancer.server.port=3001